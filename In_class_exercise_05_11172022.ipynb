{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PradeepKumarLaghavarapu-DS/PRADEEPKUMAR_INFO5731_-Fall2022/blob/main/In_class_exercise_05_11172022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWyTv71LmlXj"
      },
      "source": [
        "# **The fifth in-class-exercise (40 points in total, 11/17/2022)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qYaWf_umlXm"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#loading text data \n",
        "testing_data = pd.read_csv(r'stsa-test.txt', sep='\\t', header=None)\n",
        "training_data = pd.read_csv(r'stsa-test.txt', sep='\\t', header=None)\n",
        "\n",
        "\n",
        "def data_report(data):\n",
        "    print(data.head())\n",
        "    print(data.info())\n",
        "    print(data.describe())\n",
        "    print(data.shape)\n",
        "    print(data.dtypes)\n",
        "    print(data.isnull().sum())\n",
        "    print(data.isnull().sum().sum())\n",
        "\n",
        "data_report(training_data)\n",
        "data_report(testing_data)\n",
        "\n",
        "#cleaning the data\n",
        "def data_clean(data):\n",
        "    data.columns = ['label', 'text']\n",
        "    data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "    data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n",
        "    data['text'] = data['text'].apply((lambda x: re.sub('\\s+', ' ', x)))\n",
        "    return data\n",
        "\n",
        "#ploting the data\n",
        "def data_plot(data):\n",
        "    sns.countplot(x='label', data=data)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def split_data(data):\n",
        "    train, validate = train_test_split(data, test_size=0.2, random_state=0)\n",
        "    return train, validate\n",
        "\n",
        "def data_algorithms(train, validate):\n",
        "    #MultinominalNB\n",
        "    mnb_model = MultinomialNB()\n",
        "    mnb_model.fit(train['text'], train['label'])\n",
        "    mnb_model_pred = mnb_model.predict(validate['text'])\n",
        "    mnb_model_accuracy = accuracy_score(validate['label'], mnb_model_pred)\n",
        "    mnb_model_recall = recall_score(validate['label'], mnb_model_pred)\n",
        "    mnb_model_precision = precision_score(validate['label'], mnb_model_pred)\n",
        "    mnb_model_f1 = f1_score(validate['label'], mnb_model_pred)\n",
        "    print('MultinominalNB')\n",
        "    print('Accuracy:', mnb_model_accuracy)\n",
        "    print('Recall:', mnb_model_recall)\n",
        "    print('Precision:', mnb_model_precision)\n",
        "    print('F1 score:', mnb_model_f1)\n",
        "    print('\\n')\n",
        "    \n",
        "    #SVM\n",
        "    svc_model = SVC()\n",
        "    svc_model.fit(train['text'], train['label'])\n",
        "    svc_model_pred = svc_model.predict(validate['text'])\n",
        "    svc_model_accuracy = accuracy_score(validate['label'], svc_model_pred)\n",
        "    svc_model_recall = recall_score(validate['label'], svc_model_pred)\n",
        "    svc_model_precision = precision_score(validate['label'], svc_model_pred)\n",
        "    svc_model_f1 = f1_score(validate['label'], svc_model_pred)\n",
        "    print('SVM')\n",
        "    print('Accuracy:', svc_model_accuracy)\n",
        "    print('Recall:', svc_model_recall)\n",
        "    print('Precision:', svc_model_precision)\n",
        "    print('F1 score:', svc_model_f1)\n",
        "    print('\\n')\n",
        "    \n",
        "    #KNN\n",
        "    knn_model = KNeighborsClassifier()\n",
        "    knn_model.fit(train['text'], train['label'])\n",
        "    knn_model_pred = knn_model.predict(validate['text'])\n",
        "    knn_model_accuracy = accuracy_score(validate['label'], knn_model_pred)\n",
        "    knn_model_recall = recall_score(validate['label'], knn_model_pred)\n",
        "    knn_model_precision = precision_score(validate['label'], knn_model_pred)\n",
        "    knn_model_f1 = f1_score(validate['label'], knn_model_pred)\n",
        "    print('KNN')\n",
        "    print('Accuracy:', knn_model_accuracy)\n",
        "    print('Recall:', knn_model_recall)\n",
        "    print('Precision:', knn_model_precision)\n",
        "    print('F1 score:', knn_model_f1)\n",
        "    print('\\n')\n",
        "\n",
        "    #Decision tree\n",
        "    dt_model = DecisionTreeClassifier()\n",
        "    dt_model.fit(train['text'], train['label'])\n",
        "    dt_model_pred = dt_model.predict(validate['text'])\n",
        "    dt_model_accuracy = accuracy_score(validate['label'], dt_model_pred)\n",
        "    dt_model_recall = recall_score(validate['label'], dt_model_pred)\n",
        "    dt_model_precision = precision_score(validate['label'], dt_model_pred)\n",
        "    dt_model_f1 = f1_score(validate['label'], dt_model_pred)\n",
        "    print('Decision tree')\n",
        "    print('Accuracy:', dt_model_accuracy)\n",
        "    print('Recall:', dt_model_recall)\n",
        "    print('Precision:', dt_model_precision)\n",
        "    print('F1 score:', dt_model_f1)\n",
        "    print('\\n')\n",
        "\n",
        "    #Random Forest\n",
        "    rf_model = RandomForestClassifier()\n",
        "    rf_model.fit(train['text'], train['label'])\n",
        "    rf_model_pred = rf_model.predict(validate['text'])\n",
        "    rf_model_accuracy = accuracy_score(validate['label'], rf_model_pred)\n",
        "    rf_model_recall = recall_score(validate['label'], rf_model_pred)\n",
        "    rf_model_precision = precision_score(validate['label'], rf_model_pred)\n",
        "    rf_model_f1 = f1_score(validate['label'], rf_model_pred)\n",
        "    print('Random Forest')\n",
        "    print('Accuracy:', rf_model_accuracy)\n",
        "    print('Recall:', rf_model_recall)\n",
        "    print('Precision:', rf_model_precision)\n",
        "    print('F1 score:', rf_model_f1)\n",
        "    print('\\n')\n",
        "    \n",
        "    #XGBoost\n",
        "    xgb_model = XGBClassifier()\n",
        "    xgb_model.fit(train['text'], train['label'])\n",
        "    xgb_model_pred = xgb_model.predict(validate['text'])\n",
        "    xgb_model_accuracy = accuracy_score(validate['label'], xgb_model_pred)\n",
        "    xgb_model_recall = recall_score(validate['label'], xgb_model_pred)\n",
        "    xgb_model_precision = precision_score(validate['label'], xgb_model_pred)\n",
        "    xgb_model_f1 = f1_score(validate['label'], xgb_model_pred)\n",
        "    print('XGBoost')\n",
        "    print('Accuracy:', xgb_model_accuracy)\n",
        "    print('Recall:', xgb_model_recall)\n",
        "    print('Precision:', xgb_model_precision)\n",
        "    print('F1 score:', xgb_model_f1)\n",
        "    print('\\n')\n",
        "\n",
        "    \n",
        "def data_run():\n",
        "    result = data_algorithms(data_split(training_data)[0], data_split(testing_data)[0])\n",
        "    return result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH1XHfVso4G0",
        "outputId": "22f8bae9-f6d8-4df8-8ca1-fdfd31ba1689"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   0\n",
            "0   0 no movement , no yuks , not much of anything .\n",
            "1  0 a gob of drivel so sickly sweet , even the e...\n",
            "2  0 gangs of new york is an unapologetic mess , ...\n",
            "3  0 we never really feel involved with the story...\n",
            "4          1 this is one of polanski 's best films .\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1821 entries, 0 to 1820\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       1821 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 14.4+ KB\n",
            "None\n",
            "                                                       0\n",
            "count                                               1821\n",
            "unique                                              1821\n",
            "top     0 no movement , no yuks , not much of anything .\n",
            "freq                                                   1\n",
            "(1821, 1)\n",
            "0    object\n",
            "dtype: object\n",
            "0    0\n",
            "dtype: int64\n",
            "0\n",
            "                                                   0\n",
            "0   0 no movement , no yuks , not much of anything .\n",
            "1  0 a gob of drivel so sickly sweet , even the e...\n",
            "2  0 gangs of new york is an unapologetic mess , ...\n",
            "3  0 we never really feel involved with the story...\n",
            "4          1 this is one of polanski 's best films .\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1821 entries, 0 to 1820\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       1821 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 14.4+ KB\n",
            "None\n",
            "                                                       0\n",
            "count                                               1821\n",
            "unique                                              1821\n",
            "top     0 no movement , no yuks , not much of anything .\n",
            "freq                                                   1\n",
            "(1821, 1)\n",
            "0    object\n",
            "dtype: object\n",
            "0    0\n",
            "dtype: int64\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ala2ZMqlmlXu"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K means, \n",
        "DBSCAN,\n",
        "Hierarchical clustering. \n",
        "\n",
        "You can refer to of the codes from  the follwing link below. \n",
        "https://www.kaggle.com/karthik3890/text-clustering "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rAqYzZ7OmlXu",
        "outputId": "084bc524-f1da-4aab-9d85-d0630fb3c069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Price         Rating   Review Votes\n",
            "count  407907.000000  413840.000000  401544.000000\n",
            "mean      226.867155       3.819578       1.507237\n",
            "std       273.006259       1.548216       9.163853\n",
            "min         1.730000       1.000000       0.000000\n",
            "25%        79.990000       3.000000       0.000000\n",
            "50%       144.710000       5.000000       0.000000\n",
            "75%       269.990000       5.000000       1.000000\n",
            "max      2598.000000       5.000000     645.000000\n",
            "\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 413840 entries, 0 to 413839\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   Product Name  413840 non-null  object \n",
            " 1   Brand Name    348669 non-null  object \n",
            " 2   Price         407907 non-null  float64\n",
            " 3   Rating        413840 non-null  int64  \n",
            " 4   Reviews       413778 non-null  object \n",
            " 5   Review Votes  401544 non-null  float64\n",
            "dtypes: float64(2), int64(1), object(3)\n",
            "memory usage: 18.9+ MB\n",
            "None\n",
            "\n",
            "\n",
            "                                        Product Name Brand Name   Price  \\\n",
            "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
            "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
            "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
            "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
            "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
            "\n",
            "   Rating                                            Reviews  Review Votes  \n",
            "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
            "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
            "2       5                                       Very pleased           0.0  \n",
            "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
            "4       4  Great phone to replace my lost phone. The only...           0.0  \n",
            "\n",
            "\n",
            "Index(['Product Name', 'Brand Name', 'Price', 'Rating', 'Reviews',\n",
            "       'Review Votes'],\n",
            "      dtype='object')\n",
            "\n",
            "\n",
            "(413840, 6)\n",
            "\n",
            "\n",
            "Product Name     object\n",
            "Brand Name       object\n",
            "Price           float64\n",
            "Rating            int64\n",
            "Reviews          object\n",
            "Review Votes    float64\n",
            "dtype: object\n",
            "\n",
            "\n",
            "Product Name        0\n",
            "Brand Name      65171\n",
            "Price            5933\n",
            "Rating              0\n",
            "Reviews            62\n",
            "Review Votes    12296\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "83462\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Write your code here.\n",
        "\n",
        "\n",
        "#loading machine learning libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#Loading the data\n",
        "amazon_data = pd.read_csv(r'Amazon_Unlocked_Mobile.csv')\n",
        "\n",
        "def data_split(amazon_data):\n",
        "    #spliting the data to train and test\n",
        "    train, validate = train_test_split(amazon_data, test_size=0.2, random_state=42)\n",
        "    return train, validate\n",
        "\n",
        "def analysis_descriptive(amazon_data):\n",
        "    #descriptive analysis of the amazon data\n",
        "    print(amazon_data.describe())\n",
        "    print('\\n')\n",
        "    print(amazon_data.info())\n",
        "    print('\\n')\n",
        "    print(amazon_data.head())\n",
        "    print('\\n')\n",
        "    print(amazon_data.columns)\n",
        "    print('\\n')\n",
        "    print(amazon_data.shape)\n",
        "    print('\\n')\n",
        "    print(amazon_data.dtypes)\n",
        "    print('\\n')\n",
        "    print(amazon_data.isnull().sum())\n",
        "    print('\\n')\n",
        "    print(amazon_data.isnull().sum().sum())\n",
        "    print('\\n')\n",
        "\n",
        "analysis_descriptive(amazon_data)\n",
        "plt.scatter(amazon_data['Rating'], amazon_data['Price'])\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Price')\n",
        "plt.show()\n",
        "\n",
        "def plotting_data(amazon_data):\n",
        "    #plotting data of the amazon \n",
        "    sns.set(style=\"whitegrid\")\n",
        "    sns.set(font_scale=1.5)\n",
        "    sns.countplot(x=\"label\", data=amazon_data)\n",
        "    plt.show()\n",
        "\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "\n",
        "def methods_clustering(train, validate):\n",
        "    #clustering methods of the data\n",
        "\n",
        "    from sklearn.cluster import KMeans\n",
        "    from sklearn.cluster import DBSCAN\n",
        "\n",
        "    #Hierarchical clustering of the data\n",
        "    from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "    from scipy.cluster.hierarchy import fcluster\n",
        "\n",
        "    #K means\n",
        "    kmeans_model = KMeans(n_clusters=3, random_state=0).fit(train['Price'])\n",
        "    kmeans_model_pred = kmeans_model.predict(validate['Price'])\n",
        "    kmeans_model_accuracy = accuracy_score(validate['label'], kmeans_model_pred)\n",
        "    kmeans_model_recall = recall_score(validate['label'], kmeans_model_pred)\n",
        "    kmeans_model_precision = precision_score(validate['label'], kmeans_model_pred)\n",
        "    kmeans_model_f1 = f1_score(validate['label'], kmeans_model_pred)\n",
        "    print('K means')\n",
        "    print('Accuracy:', kmeans_model_accuracy)\n",
        "    print('Recall:', kmeans_model_recall)\n",
        "    print('Precision:', kmeans_model_precision)\n",
        "    print('F1 score:', kmeans_model_f1)\n",
        "    print('\\n')\n",
        "\n",
        "    #DBSCAN\n",
        "    dbscan_model = DBSCAN(eps=0.5, min_samples=5).fit(train['Price'])\n",
        "    dbscan_model_pred = dbscan_model.predict(validate['Price'])\n",
        "    dbscan_model_accuracy = accuracy_score(validate['label'], dbscan_model_pred)\n",
        "    dbscan_model_recall = recall_score(validate['label'], dbscan_model_pred)\n",
        "    dbscan_model_precision = precision_score(validate['label'], dbscan_model_pred)\n",
        "    dbscan_model_f1 = f1_score(validate['label'], dbscan_model_pred)\n",
        "    print('DBSCAN')\n",
        "    print('Accuracy:', dbscan_model_accuracy)\n",
        "    print('Recall:', dbscan_model_recall)\n",
        "    print('Precision:', dbscan_model_precision)\n",
        "    print('F1 score:', dbscan_model_f1)\n",
        "    print('\\n')\n",
        "\n",
        "    #Hierarchical clustering of the data\n",
        "    Z = linkage(train['Price'], 'ward')\n",
        "    plt.figure(figsize=(25, 10))\n",
        "    dendrogram(Z, leaf_rotation=90, leaf_font_size=8, labels=train['label'])\n",
        "    plt.show()\n",
        "\n",
        "def data_run():\n",
        "    result = methods_clustering(data_split(training_data)[0], data_split(testing_data)[0])\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxrrRScPmlXv"
      },
      "source": [
        "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rCNm0VNgmlXv"
      },
      "outputs": [],
      "source": [
        "#You can write you answer here. (No code needed)\n",
        "\n",
        "\n",
        "# Finding clusters in data is done using a sort of unsupervised learning method called K means. \n",
        "# Similarly to other unsupervised learning algorithms, DBSCAN seeks out clusters that are not necessarily connected. \n",
        "# A supervised learning approach called hierarchical clustering is used to build a hierarchical tree of groups. \n",
        "# Clusters are the groupings at the bottom of the tree, and superclusters are the groups above them. \n",
        "# Members of each category in the hierarchy are similar to one another. A similarity matrix—a group of values that gauges how \n",
        "# similar two objects are to one another—determines this similarity.To identify groups that are similar to one another,\n",
        "# hierarchical clustering is frequently utilized. In order to better comprehend the structure of the data, it is also utilized to\n",
        "# establish a hierarchy of groupings. Hierarchical clustering, DBSCAN, and K means are examples of unsupervised learning methods.\n",
        "# To detect clusters in the data, they all employ data."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}